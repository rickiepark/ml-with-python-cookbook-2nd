{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a48ed95-2289-47fd-8092-e7825ea46724",
   "metadata": {},
   "source": [
    "# 21장. 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a25d2-cd1e-43a5-b890-f5de8cdd464f",
   "metadata": {},
   "source": [
    "<table align=\"left\"><tr><td>\n",
    "<a href=\"https://colab.research.google.com/github/rickiepark/ml-with-python-cookbook-2nd/blob/main/ch21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b57e3e-dbfb-454d-aa33-31f5452d0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import matplotlib\n",
    "import lightening\n",
    "import ray\n",
    "import torchvis\n",
    "\n",
    "print('numpy', np.__version__)\n",
    "print('sklearn', sklearn.__version__)\n",
    "print('torch', torch.__version__)\n",
    "print('matplotlib', matplotlib.__version__)\n",
    "print('lightening', lightening.__version__)\n",
    "print('ray', ray.__version__)\n",
    "print('torchvis', torchvis.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d5313-72a8-48e4-b92f-fde54d84a240",
   "metadata": {},
   "source": [
    "## 21.1 파이토치 자동미분 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a7456c-c5d2-4a23-a422-729f11fe9da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 라이브러리를 임포트합니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 하나의 행으로 벡터를 만듭니다.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tensor_row \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "\n",
    "# 그레이언트가 필요한 토치 텐서를 만듭니다.\n",
    "t = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# 정방향 계산을 모방한 텐서 연산을 수행합니다.\n",
    "tensor_sum = t.sum()\n",
    "\n",
    "# 역전파를 수행합니다.\n",
    "tensor_sum.backward()\n",
    "\n",
    "# 그레이디언트를 확인합니다.\n",
    "t.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92f4d6-4d15-45d4-9d53-cd5c21740a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689157b2-dd4e-4069-918d-fa4030585630",
   "metadata": {},
   "source": [
    "## 21.2 신경망을 위해 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa2362-16d6-4abc-a9b0-b3c085599ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                     [-200.2, -234.1],\n",
    "                     [5000.5, 150.1],\n",
    "                     [6000.6, -125.1],\n",
    "                     [9000.9, -673.1]])\n",
    "\n",
    "# 스케일링 객체를 만듭니다.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 특성을 변환합니다.\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 특성을 확인합니다.\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9e44-acd4-44aa-af1d-0f9888cc7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "\n",
    "# 특성을 만듭니다.\n",
    "torch_features = torch.tensor([[-100.1, 3240.1],\n",
    "                               [-200.2, -234.1],\n",
    "                               [5000.5, 150.1],\n",
    "                               [6000.6, -125.1],\n",
    "                               [9000.9, -673.1]], requires_grad=True)\n",
    "\n",
    "# 평균과 표준 편차를 계산합니다.\n",
    "mean = torch_features.mean(0, keepdim=True)\n",
    "standard_deviation = torch_features.std(0, unbiased=False, keepdim=True)\n",
    "\n",
    "# 평균과 표준 편차를 사용해 특성을 표준화합니다.\n",
    "torch_features_standardized = torch_features - mean\n",
    "torch_features_standardized /= standard_deviation\n",
    "\n",
    "# 표준화된 특성을 확인합니다.\n",
    "torch_features_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088effb-f419-486b-bb00-9fab8075cea8",
   "metadata": {},
   "source": [
    "## 21.3 신경망 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d871baa7-7907-47e4-84cf-b0f5e37e50a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 라이브러리를 임포트합니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 텐서를 만듭니다.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m      6\u001b[0m [\n\u001b[1;32m      7\u001b[0m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수, 옵티마이저를 정의합니다.\n",
    "loss_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(network.parameters())\n",
    "\n",
    "# 신경망을 확인합니다.\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02983da4-1d45-4300-a7ee-9ac0d46515b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화하고 확인합니다.\n",
    "SimpleNeuralNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e2e9e-f51d-4708-9f64-e840bf742ac0",
   "metadata": {},
   "source": [
    "## 21.4 이진 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3489c-5b6c-43c3-8b3a-f0b4678b9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 파이토치 2.0의 옵티마이저를 사용해 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())\n",
    "\n",
    "# 신경망을 평가합니다.\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"테스트 세트 손실:\", test_loss.item(), \"\\t테스트 세트 정확도:\",\n",
    "        test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdac14c-68bd-4c95-9067-12be6572163c",
   "metadata": {},
   "source": [
    "## 21.5 다중 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cd61b-8bdc-4e73-a217-ca3188589203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N_CLASSES=3\n",
    "EPOCHS=3\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=N_CLASSES, n_informative=9,\n",
    "    n_redundant=0, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.nn.functional.one_hot(torch.from_numpy(target_train).long(),\n",
    "    num_classes=N_CLASSES).float()\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.nn.functional.one_hot(torch.from_numpy(target_test).long(),\n",
    "    num_classes=N_CLASSES).float()\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,3),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())\n",
    "\n",
    "# Evaluate neural network\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"테스트 세트 손실:\", test_loss.item(), \"\\t테스트 세트 정확도:\",\n",
    "        test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9c34e-ee5c-4205-95de-30c84333b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 행렬을 확인합니다.\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a030d03-1188-4119-ade0-e38e3182444c",
   "metadata": {},
   "source": [
    "## 21.6 회귀 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035927e-106a-4319-90f1-347d79ebe25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS=5\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_regression(n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1,1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1,1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())\n",
    "\n",
    "# 신경망을 평가합니다.\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = float(criterion(output, y_test))\n",
    "    print(\"테스트 세트 MSE:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951c8d3-c66f-44ba-ae36-e50ff2727a71",
   "metadata": {},
   "source": [
    "## 21.7 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d67cd-6a14-4d4b-9b34-9b51ca1ac250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())\n",
    "\n",
    "# 예측을 만듭니다.\n",
    "with torch.no_grad():\n",
    "    predicted_class = network.forward(x_train).round()\n",
    "\n",
    "predicted_class[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea676d8-689b-4f93-95d6-9b6ffc17e596",
   "metadata": {},
   "source": [
    "## 21.8 훈련 기록 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac323d6-85e6-4f0d-9ea8-1b2f20d3388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 8\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_output = network(x_train)\n",
    "        train_loss = criterion(output, target)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        test_output = network(x_test)\n",
    "        test_loss = criterion(test_output, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "# 손실 기록을 시각화합니다.\n",
    "epochs = range(0, epochs)\n",
    "plt.plot(epochs, train_losses, \"r--\")\n",
    "plt.plot(epochs, test_losses, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d568be-97b7-4559-bd8b-41a982441b41",
   "metadata": {},
   "source": [
    "## 21.9 가중치 규제로 과대적합 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa6409-2033-4f26-8368-d0f3766a6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 신경망을 평가합니다.\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"테스트 세트 손실:\", test_loss.item(), \"\\t테스트 세트 정확도:\",\n",
    "        test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d681864-7e63-4352-8523-d03fec466ba8",
   "metadata": {},
   "source": [
    "## 21.10 조기종료로 과대적합 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074f2cf-77ea-4515-b8fc-979c9b710fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "class LightningNetwork(pl.LightningModule):\n",
    "    def __init__(self, network):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.metric = nn.functional.binary_cross_entropy\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step는 훈련 루프를 정의합니다.\n",
    "        data, target = batch\n",
    "        output = self.network(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = LightningNetwork(SimpleNeuralNet())\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "trainer = pl.Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "    patience=3)], max_epochs=1000)\n",
    "trainer.fit(model=network, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa30d1-30be-4998-b6cd-988efee1e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 훈련합니다.\n",
    "trainer = pl.Trainer(max_epochs=1000)\n",
    "trainer.fit(model=network, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449560d-1889-4cc1-b547-e0989ca0e568",
   "metadata": {},
   "source": [
    "## 21.11 드롭아웃으로 과대적합 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1aca2-67a8-4c97-b678-71922b3f7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Dropout(0.1), # Drop 10% of neurons\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())\n",
    "\n",
    "# 신경망을 평가합니다.\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"테스트 세트 손실:\", test_loss.item(), \"\\t테스트 세트 정확도:\",\n",
    "        test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a987b3-486c-4ae5-9b3a-7971e99c743a",
   "metadata": {},
   "source": [
    "## 21.12 모델 훈련 진행 과정을 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b94574-ce2a-4470-b357-fc66a0bb18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Dropout(0.1), # Drop 10% of neurons\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 매 에포크 종료 후 모델을 저장합니다.\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': network.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            },\n",
    "            \"model.pt\"\n",
    "        )\n",
    "    print(\"에포크:\", epoch+1, \"\\t손실:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b648c83-9120-4b02-922e-83e55c492cc6",
   "metadata": {},
   "source": [
    "## 21.13 신경망 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76549cd9-e52a-405c-9d4d-eac7723ce53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, layer_size_1=10, layer_size_2=10):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, layer_size_1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(layer_size_1, layer_size_2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(layer_size_2, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "config = {\n",
    "    \"layer_size_1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "    \"layer_size_2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=1000,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=[\"layer_size_1\", \"layer_size_2\", \"lr\"],\n",
    "    metric_columns=[\"loss\"]\n",
    ")\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "def train_model(config, epochs=3):\n",
    "    network = SimpleNeuralNet(config[\"layer_size_1\"], config[\"layer_size_2\"])\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "    # 모델을 컴파일합니다.\n",
    "    network = torch.compile(network)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tune.report(loss=(loss.item()))\n",
    "\n",
    "result = tune.run(\n",
    "    train_model,\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    config=config,\n",
    "    num_samples=1,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter\n",
    ")\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(\"최상의 구성: {}\".format(best_trial.config))\n",
    "print(\"최상의 구성에서 최종 검증 손실: {}\".format(\n",
    "    best_trial.last_result[\"loss\"]))\n",
    "\n",
    "best_trained_model = SimpleNeuralNet(best_trial.config[\"layer_size_1\"],\n",
    "    best_trial.config[\"layer_size_2\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2e08d-e345-4c5b-98c9-4b17a2be27d3",
   "metadata": {},
   "source": [
    "## 21.14 신경망 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918d079-0c93-447c-9e76-33b61c8ec0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from torchviz import make_dot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 파이토치 텐서로 변환합니다.\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Sequential 클래스를 사용해 신경망을 정의합니다.\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# 신경망을 초기화합니다.\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# 손실 함수와 옵티마이저를 정의합니다.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# 데이터 로더를 정의합니다.\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "network = torch.compile(network)\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "make_dot(output.detach(), params=dict(\n",
    "    list(\n",
    "        network.named_parameters()\n",
    "        )\n",
    "      )\n",
    "    ).render(\n",
    "        \"simple_neural_network\",\n",
    "        format=\"png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
