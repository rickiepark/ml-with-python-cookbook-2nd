{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWrYYdGSk_J9"
      },
      "source": [
        "# 16장. 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1SZ8V88k_KB"
      },
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/ml-with-python-cookbook-2nd/blob/main/ch16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gPqyRD_uk_KB",
        "outputId": "d993ef6a-d52d-4147-a2a3-d86e5bdae8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 1.25.2\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "print('numpy', np.__version__)\n",
        "print('sklearn', sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZMKkEek_KD"
      },
      "source": [
        "## 16.1 이진 분류기 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zszf7avMk_KD"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터를 로드하고 두 개의 클래스만 선택합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data[:100,:]\n",
        "target = iris.target[:100]\n",
        "\n",
        "# 특성을 표준화합니다.\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegression(random_state=0)\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VKexyvU4k_KE",
        "outputId": "e1d4f602-ee68-41d4-e636-503eefd286b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 새로운 샘플을 만듭니다.\n",
        "new_observation = [[.5, .5, .5, .5]]\n",
        "\n",
        "# 클래스를 예측합니다.\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Z1PNl-tk_KF",
        "outputId": "9012334d-b8ff-412b-a48a-f96e3c7e381e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17738424, 0.82261576]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 예측 확률을 확인합니다.\n",
        "model.predict_proba(new_observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2LKhgqvk_KF"
      },
      "source": [
        "## 16.2 다중 클래스 분류기 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "id": "LFLKkQyck_KG"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 특성을 표준화합니다.\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# OVR 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegression(random_state=0, multi_class=\"ovr\")\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mId68Z4Rk_KG"
      },
      "source": [
        "## 16.3 규제로 분산 줄이기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "JA9GmsaDk_KG"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 특성을 표준화합니다.\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegressionCV(\n",
        "    penalty='l2', Cs=10, random_state=0, n_jobs=-1)\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHi8ikHdk_KH"
      },
      "source": [
        "### 붙임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8fmQzXkFk_KH",
        "outputId": "7e4c1a83-6659-4dde-e845-599291868f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21.5443469, 21.5443469, 21.5443469])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "logistic_regression.C_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8VNUtebk_KH"
      },
      "source": [
        "## 16.4 대용량 데이터에서 분류기 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5mVJkbhuk_KH"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 특성을 표준화합니다.\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegression(random_state=0, solver=\"sag\")\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0H1nVqxrk_KI",
        "outputId": "ac1decf4-8863-4aac-f7ff-49f2bf492f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2f4d52625860>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 에러 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m LogisticRegression(random_state=0, solver='liblinear', penalty=None).fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     features_standardized, target)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                     \u001b[0;34m\" = {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                 )\n\u001b[0;32m-> 1216\u001b[0;31m             self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[1;32m   1225\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_get_liblinear_solver_type\u001b[0;34m(multi_class, penalty, loss, dual)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msolver_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0;34m\"Unsupported set of arguments: %s, Parameters: penalty=%r, loss=%r, dual=%r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False"
          ]
        }
      ],
      "source": [
        "# 에러 발생\n",
        "LogisticRegression(random_state=0, solver='liblinear', penalty=None).fit(\n",
        "    features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "weLtSDujk_KI",
        "outputId": "f26f7780-6791-45fc-c7f0-cd0f88f8b3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-39b524231ba9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 에러 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m LogisticRegression(random_state=0, solver='sag', penalty='l1').fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     features_standardized, target)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"elasticnet\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# TODO(1.4): Remove \"none\" option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;34m\"Solver %s supports only 'l2' or 'none' penalties, got %s penalty.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty."
          ]
        }
      ],
      "source": [
        "# 에러 발생\n",
        "LogisticRegression(random_state=0, solver='sag', penalty='l1').fit(\n",
        "    features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEFNrJ4sk_KI"
      },
      "source": [
        "## 16.5 불균형한 클래스 다루기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "peCFmbO5k_KJ"
      },
      "outputs": [],
      "source": [
        "# 라이브러리를 임포트합니다.\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터를 로드합니다.\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# 처음 40개 샘플을 제거하여 불균형한 클래스를 만듭니다.\n",
        "features = features[40:,:]\n",
        "target = target[40:]\n",
        "\n",
        "# 타깃 벡터에서 0이 아닌 클래스는 모두 1로 만듭니다.\n",
        "target = np.where((target == 0), 0, 1)\n",
        "\n",
        "# 특성을 표준화합니다.\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "\n",
        "# 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegression(random_state=0, class_weight=\"balanced\")\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRuOIxhDk_KJ"
      },
      "source": [
        "### 붙임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mMP2nSerk_KJ",
        "outputId": "dc11f8c7-c50e-4a1c-9556-eb1f0a009a5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.5 , 0.55])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# 클래스 레이블이 0, 1인 데이터의 클래스 가중치를 계산합니다.\n",
        "compute_class_weight('balanced', classes=[0, 1], y=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QJb2ZL4Rk_KJ"
      },
      "outputs": [],
      "source": [
        "# 10:1의 클래스 가중치를 부여한 로지스틱 회귀 모델을 만듭니다.\n",
        "logistic_regression = LogisticRegression(random_state=0, class_weight={0:10, 1:1})\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}